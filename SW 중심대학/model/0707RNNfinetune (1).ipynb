{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fc461d9-6625-4912-843a-22c903d2a0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (0.59.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from pooch>=1.1->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torchmetrics) (1.24.3)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torchmetrics) (2.3.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torchmetrics) (0.11.3.post0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "!pip install torchmetrics\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bc47dc-a3a6-426e-8302-388d652888c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, TimeDistributed, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f4d5a96-6643-4356-bdd0-3ffc830401ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401ec64c-ecb9-484a-bd39-d4b724a1e7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 13\n",
    "    # Dataset\n",
    "    ROOT_FOLDER = r\"C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\"\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 128\n",
    "    N_EPOCHS = 5\n",
    "    LR = 1e-4\n",
    "    DROPOUT_RATE = 0.3\n",
    "    # Others\n",
    "    SEED = 42\n",
    "    \n",
    "CONFIG = Config()\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CONFIG.SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6b92f1-bd9e-4e87-9cbc-390702f8ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame:\n",
      "             id                                               path label\n",
      "6804   SNGJTJQG  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  fake\n",
      "3734   LIYTDJZZ  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  fake\n",
      "55413  HAMPQOIN  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  real\n",
      "10741  UCJMLYVH  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  fake\n",
      "33027  EUKZRQPD  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  real\n",
      "\n",
      "Validation DataFrame:\n",
      "             id                                               path label\n",
      "49798  PUOXNOKJ  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  real\n",
      "54292  GXOIPDJP  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  fake\n",
      "40359  FOEQKPPR  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  fake\n",
      "50441  IYASAVDT  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  real\n",
      "37723  VLWIXPTC  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./train...  real\n",
      "\n",
      "Test DataFrame:\n",
      "           id                                               path\n",
      "0  TEST_00000  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./test/...\n",
      "1  TEST_00001  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./test/...\n",
      "2  TEST_00002  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./test/...\n",
      "3  TEST_00003  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./test/...\n",
      "4  TEST_00004  C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\\./test/...\n"
     ]
    }
   ],
   "source": [
    "# Load your DataFrame\n",
    "train_df = pd.read_csv('C:/Users/KimDongyoung/Downloads/SW중심대학/train.csv')\n",
    "test_df = pd.read_csv('C:/Users/KimDongyoung/Downloads/SW중심대학/test.csv')\n",
    "submission_df = pd.read_csv('C:/Users/KimDongyoung/Downloads/SW중심대학/sample_submission.csv')\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "train, val = train_test_split(train_df, test_size=0.2, random_state=CONFIG.SEED)\n",
    "\n",
    "# Ensure paths are updated\n",
    "def update_path(df, root_folder):\n",
    "    df['path'] = df['path'].apply(lambda x: os.path.join(root_folder, x))\n",
    "    return df\n",
    "\n",
    "train = update_path(train, CONFIG.ROOT_FOLDER)\n",
    "val = update_path(val, CONFIG.ROOT_FOLDER)\n",
    "test_df = update_path(test_df, CONFIG.ROOT_FOLDER)\n",
    "\n",
    "print(\"Train DataFrame:\")\n",
    "print(train.head())\n",
    "\n",
    "print(\"\\nValidation DataFrame:\")\n",
    "print(val.head())\n",
    "\n",
    "print(\"\\nTest DataFrame:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498c9b0b-b089-410e-b48c-7c6f2e7bd36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44350it [11:21, 65.08it/s]\n",
      "11088it [02:39, 69.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define existing functions\n",
    "def load_audio(file_path, sr=CONFIG.SR):\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    return y, sr\n",
    "\n",
    "def extract_features(y, sr, n_mfcc=CONFIG.N_MFCC):\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    return mfcc.T  # Transpose to get time steps as rows\n",
    "\n",
    "def get_mfcc_feature(df, train_mode=True):\n",
    "    features = []\n",
    "    labels = []\n",
    "    max_len = 0  # To keep track of the maximum sequence length for padding\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        file_path = row['path']\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        y, sr = load_audio(file_path)\n",
    "        mfcc = extract_features(y, sr)\n",
    "        features.append(mfcc)\n",
    "        if mfcc.shape[0] > max_len:\n",
    "            max_len = mfcc.shape[0]\n",
    "\n",
    "        if train_mode:\n",
    "            label = row['label']\n",
    "            label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
    "            label_vector[0 if label == 'fake' else 1] = 1\n",
    "            labels.append(label_vector)\n",
    "    \n",
    "    # Pad sequences to have the same length\n",
    "    features = [np.pad(f, ((0, max_len - f.shape[0]), (0, 0)), mode='constant') for f in features]\n",
    "\n",
    "    if train_mode:\n",
    "        return features, labels\n",
    "    return features\n",
    "\n",
    "train_mfcc, train_labels = get_mfcc_feature(train, True)\n",
    "val_mfcc, val_labels = get_mfcc_feature(val, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72902512-10b3-4db3-b462-30e1a35e59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, mfcc, label):\n",
    "        self.mfcc = mfcc\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            return self.mfcc[index], self.label[index]\n",
    "        return self.mfcc[index]\n",
    "\n",
    "train_dataset = CustomDataset(train_mfcc, train_labels)\n",
    "val_dataset = CustomDataset(val_mfcc, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71301812-c72f-4cb5-804a-c6de89fe4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bbfb800-300c-4fc9-8931-c244d5b7ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RNN Model with multiple LSTM layers and batch normalization\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim=CONFIG.N_MFCC, hidden_dim=128, num_layers=2, output_dim=CONFIG.N_CLASSES, dropout_rate=CONFIG.DROPOUT_RATE):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc1 = nn.Linear(hidden_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.batch_norm(x[:, -1, :])  # Apply batch normalization to the output of the last time step\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, device, patience=5):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    \n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "    early_stop_count = 0\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=2, verbose=True)\n",
    "    \n",
    "    for epoch in range(1, CONFIG.N_EPOCHS + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for features, labels in tqdm(train_loader):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        val_loss, val_score = validate(model, criterion, val_loader, device)\n",
    "        train_loss_mean = np.mean(train_loss)\n",
    "        \n",
    "        print(f'Epoch [{epoch}], Train Loss: [{train_loss_mean:.5f}], Val Loss: [{val_loss:.5f}], Val AUC: [{val_score:.5f}]')\n",
    "        \n",
    "        scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "        \n",
    "        if val_score > best_val_score:\n",
    "            best_val_score = val_score\n",
    "            best_model = model\n",
    "            early_stop_count = 0\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "        \n",
    "        if early_stop_count >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a850b2a-4c15-4c2e-8a6a-3fbade6da01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "            loss = criterion(probs, labels)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    val_loss_mean = np.mean(val_loss)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    \n",
    "    auc_score = roc_auc_score(all_labels, all_probs, average='macro')\n",
    "    \n",
    "    return val_loss_mean, auc_score\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features in test_loader:\n",
    "            features = features.float().to(device)\n",
    "            probs = model(features)\n",
    "            predictions.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d526a63-ef6b-445d-975d-708af14003ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2097c60a-dc81-4211-80cf-c13317c50d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 347/347 [21:42<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss: [0.69661], Val Loss: [0.69339], Val AUC: [0.50232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 347/347 [21:51<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss: [0.69486], Val Loss: [0.69348], Val AUC: [0.50336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 347/347 [21:51<00:00,  3.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss: [0.69459], Val Loss: [0.69334], Val AUC: [0.51276]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 347/347 [21:41<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss: [0.69418], Val Loss: [0.69328], Val AUC: [0.53636]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 347/347 [21:15<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss: [0.69431], Val Loss: [0.69324], Val AUC: [0.50942]\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model = RNNModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG.LR)\n",
    "\n",
    "best_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81973dc9-9e41-4e0d-a11e-8ea45ea9543b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [28:27, 29.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the test dataset\n",
    "test_mfcc = get_mfcc_feature(test_df, False)\n",
    "test_dataset = CustomDataset(test_mfcc, None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG.BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24a8d116-e07a-462b-b327-6e611c7b0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the test set\n",
    "predictions = inference(best_model, test_loader, device)\n",
    "\n",
    "# Prepare the submission file\n",
    "submission_df['label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f18ab680-1181-4c0b-be28-fedf065d1fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.082641</td>\n",
       "      <td>0.811870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.405881</td>\n",
       "      <td>0.874013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.483285</td>\n",
       "      <td>0.890418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.060824</td>\n",
       "      <td>0.992021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.140666</td>\n",
       "      <td>0.928351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      fake      real\n",
       "0  TEST_00000  0.082641  0.811870\n",
       "1  TEST_00001  0.405881  0.874013\n",
       "2  TEST_00002  0.483285  0.890418\n",
       "3  TEST_00003  0.060824  0.992021\n",
       "4  TEST_00004  0.140666  0.928351"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(os.path.join(CONFIG.ROOT_FOLDER, 'sample_submission.csv'))\n",
    "submit.iloc[:, 1:] = predictions\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "421dee29-dd2c-45f0-9f90-4c5156d9d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(CONFIG.ROOT_FOLDER, '0707_submit.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c1f3f-5d42-4dbd-b511-7dbfccec92d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701bdd76-094e-4ead-9370-6ba91141728d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b6209-d0da-47b0-8b40-afba9638b2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

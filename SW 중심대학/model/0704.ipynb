{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08169b2-7670-4e8c-9594-05f22632d851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (0.59.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.7.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from pooch>=1.1->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.6.2)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (1.4.0.post0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torchmetrics) (1.24.3)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torchmetrics) (2.3.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torchmetrics) (0.11.3.post0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->torchmetrics) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kimdongyoung\\anaconda\\lib\\site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed8fe3c-3d8a-40e2-a489-34c0efa56c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba49885-2334-4ca7-bf88-657e969ff2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a8cb17-59f1-43ec-9ce9-fbc0a02cb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 13\n",
    "    # Dataset\n",
    "    ROOT_FOLDER = r\"C:\\Users\\KimDongyoung\\Downloads\\SW중심대학\"\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 128\n",
    "    N_EPOCHS = 10\n",
    "    LR = 1e-4\n",
    "    DROPOUT_RATE = 0.3\n",
    "    # Others\n",
    "    SEED = 42\n",
    "    \n",
    "CONFIG = Config()\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CONFIG.SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48432761-45d3-4778-a658-63decf6c3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_csv(os.path.join(CONFIG.ROOT_FOLDER, 'train.csv'))\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CONFIG.SEED)\n",
    "\n",
    "# Update the 'path' column to have the full path\n",
    "train['path'] = train['path'].apply(lambda x: os.path.join(CONFIG.ROOT_FOLDER, x))\n",
    "val['path'] = val['path'].apply(lambda x: os.path.join(CONFIG.ROOT_FOLDER, x))\n",
    "\n",
    "# Ensure test paths are also updated\n",
    "test = pd.read_csv(os.path.join(CONFIG.ROOT_FOLDER, 'test.csv'))\n",
    "test['path'] = test['path'].apply(lambda x: os.path.join(CONFIG.ROOT_FOLDER, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4095fa87-3160-439f-8b3f-6bbca3a638a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_feature(df, train_mode=True):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        file_path = row['path']\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        # Load audio file using librosa\n",
    "        y, sr = librosa.load(file_path, sr=CONFIG.SR)\n",
    "        \n",
    "        # Extract MFCC features using librosa\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
    "        mfcc = np.mean(mfcc.T, axis=0)\n",
    "        features.append(mfcc)\n",
    "\n",
    "        if train_mode:\n",
    "            label = row['label']\n",
    "            label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
    "            label_vector[0 if label == 'fake' else 1] = 1\n",
    "            labels.append(label_vector)\n",
    "\n",
    "    if train_mode:\n",
    "        return features, labels\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ead9b52-91c6-4809-b22c-3c1ed68520b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44350it [10:23, 71.18it/s]\n",
      "11088it [03:05, 59.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Call the function with the updated paths\n",
    "train_mfcc, train_labels = get_mfcc_feature(train, True)\n",
    "val_mfcc, val_labels = get_mfcc_feature(val, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f2891a6-3bb0-43c8-82b3-f057b844d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, mfcc, label):\n",
    "        self.mfcc = mfcc\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            return self.mfcc[index], self.label[index]\n",
    "        return self.mfcc[index]\n",
    "\n",
    "train_dataset = CustomDataset(train_mfcc, train_labels)\n",
    "val_dataset = CustomDataset(val_mfcc, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fffbc96-5ca2-4bb7-81ca-38c620ee01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99aa8e87-699d-4a34-bb43-ab99ea317bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=CONFIG.N_MFCC, hidden_dim=256, output_dim=CONFIG.N_CLASSES, dropout_rate=CONFIG.DROPOUT_RATE):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Add dropout\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)  # Add dropout\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8217823d-2fb1-4a89-a10d-801c0a206c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, val_loader, device, patience=5):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    \n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "    early_stop_count = 0\n",
    "    \n",
    "    for epoch in range(1, CONFIG.N_EPOCHS+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for features, labels in tqdm(iter(train_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val AUC : [{_val_score:.5f}]')\n",
    "            \n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "            early_stop_count = 0  # Reset early stopping counter\n",
    "        else:\n",
    "            early_stop_count += 1\n",
    "        \n",
    "        if early_stop_count >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65ebf89c-9a4e-447f-8164-9b58b1d2e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 227.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 647.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [1.83482] Val Loss : [0.57354] Val AUC : [0.82329]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 249.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 610.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.67904] Val Loss : [0.59290] Val AUC : [0.83005]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 246.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 640.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.58770] Val Loss : [0.51935] Val AUC : [0.86486]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 249.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 679.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.53500] Val Loss : [0.46260] Val AUC : [0.88943]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 233.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 571.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.49114] Val Loss : [0.42225] Val AUC : [0.90443]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 239.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 601.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6], Train Loss : [0.46206] Val Loss : [0.39219] Val AUC : [0.91386]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 236.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 586.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7], Train Loss : [0.43829] Val Loss : [0.38906] Val AUC : [0.92226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 236.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 586.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8], Train Loss : [0.42000] Val Loss : [0.36865] Val AUC : [0.92766]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 234.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 560.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9], Train Loss : [0.40330] Val Loss : [0.34534] Val AUC : [0.93220]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 347/347 [00:01<00:00, 231.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 580.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10], Train Loss : [0.39058] Val Loss : [0.33657] Val AUC : [0.93518]\n"
     ]
    }
   ],
   "source": [
    "def multiLabel_AUC(y_true, y_scores):\n",
    "    auc_scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        auc = roc_auc_score(y_true[:, i], y_scores[:, i])\n",
    "        auc_scores.append(auc)\n",
    "    mean_auc_score = np.mean(auc_scores)\n",
    "    return mean_auc_score\n",
    "    \n",
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(iter(val_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "            \n",
    "            loss = criterion(probs, labels)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        all_probs = np.concatenate(all_probs, axis=0)\n",
    "        \n",
    "        # Calculate AUC score\n",
    "        auc_score = multiLabel_AUC(all_labels, all_probs)\n",
    "    \n",
    "    return _val_loss, auc_score\n",
    "\n",
    "model = MLP()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CONFIG.LR)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b5e38c-eb26-4682-aaa7-eeaa3a7ab312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [16:18, 51.08it/s]\n"
     ]
    }
   ],
   "source": [
    "test_mfcc = get_mfcc_feature(test, False)\n",
    "test_dataset = CustomDataset(test_mfcc, None)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fddfa05-5533-490c-9450-0af40e6e20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for features in tqdm(iter(test_loader)):\n",
    "            features = features.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bceb5b0-c156-463e-ac44-da7ccd823b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 391/391 [00:00<00:00, 849.75it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5679ff65-7f55-4f6c-bb0f-284610d6490b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.458532</td>\n",
       "      <td>0.534064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.126282</td>\n",
       "      <td>0.875924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.340868</td>\n",
       "      <td>0.656731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.050330</td>\n",
       "      <td>0.950279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.390456</td>\n",
       "      <td>0.604165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      fake      real\n",
       "0  TEST_00000  0.458532  0.534064\n",
       "1  TEST_00001  0.126282  0.875924\n",
       "2  TEST_00002  0.340868  0.656731\n",
       "3  TEST_00003  0.050330  0.950279\n",
       "4  TEST_00004  0.390456  0.604165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(os.path.join(CONFIG.ROOT_FOLDER, 'sample_submission.csv'))\n",
    "submit.iloc[:, 1:] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11e94f06-4bc8-41a5-8791-5d55a0b7859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(CONFIG.ROOT_FOLDER, '0704_submit.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bc4f9a-1c69-451f-8951-2ff2a315bf34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

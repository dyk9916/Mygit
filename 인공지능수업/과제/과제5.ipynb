{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d87e2f8",
   "metadata": {},
   "source": [
    "### CNN에 대한 구조와 동작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a062906f",
   "metadata": {},
   "source": [
    "CNN의 구조  \n",
    "CNN은 입력층, 합성곱층(Convolutional Layer), 활성화 함수(Activation Function), 풀링층(Pooling Layer), 완전 연결층(Fully Connected Layer), 출력층(Output Layer)으로 구성된다.\n",
    "\n",
    "1 입력층 (Input Layer)\n",
    "이미지를 입력으로 받는 층이다. 입력 이미지의 크기와 채널 수(예: 흑백 이미지 1채널, 컬러 이미지 3채널)에 따라 텐서의 형상이 결정된다. 예를 들어, 28x28의 흑백 이미지는 1x28x28 형태로 입력된다.\n",
    "\n",
    "2 합성곱층 (Convolutional Layer)\n",
    "합성곱층은 필터(커널)를 사용하여 입력 이미지에서 에지, 코너, 텍스처 등의 특징을 추출한다. 필터는 학습 가능한 파라미터이며, 슬라이딩 방식으로 이미지 위를 이동하며 연산을 수행한다. 각 필터는 특정한 패턴을 감지하며, 그 결과는 특징 맵(feature map)으로 출력된다.\n",
    "\n",
    "3 활성화 함수 (Activation Function)\n",
    "합성곱 연산 후에는 비선형성을 부여하기 위해 활성화 함수가 적용된다. 대표적으로 ReLU(Rectified Linear Unit) 함수가 사용되며, 이는 입력값이 0 이하일 경우 0, 0 이상일 경우 그대로 출력한다. 이를 통해 모델이 복잡한 함수를 학습할 수 있게 된다.\n",
    "\n",
    "4 풀링층 (Pooling Layer)\n",
    "풀링층은 특징 맵의 크기를 줄이면서 중요한 정보만 남긴다. 일반적으로 Max Pooling이 사용되며, 특정 영역 내 최대값을 선택한다. 이 과정을 통해 연산량이 줄어들고, 과적합을 방지하는 데 도움이 된다.\n",
    "\n",
    "5 완전 연결층 (Fully Connected Layer)\n",
    "풀링된 데이터를 1차원 벡터로 변환한 후 완전 연결층에 전달한다. 이 층에서는 전체 뉴런이 서로 연결되어 있으며, 고차원의 특징을 조합해 분류를 수행한다.\n",
    "\n",
    "6 출력층 (Output Layer)\n",
    "최종적으로 softmax 함수를 통해 각 클래스에 대한 확률을 출력한다. 이 결과를 바탕으로 입력 이미지가 어떤 클래스에 속하는지를 예측하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af89eee",
   "metadata": {},
   "source": [
    "CNN의 작동 원리   \n",
    "CNN은 다음과 같은 절차로 입력 데이터를 처리한다:\n",
    "\n",
    "특징 추출: 합성곱 연산을 통해 입력 이미지로부터 국소적인 특징(에지, 질감 등)을 추출한다.\n",
    "\n",
    "비선형 변환: ReLU 활성화 함수를 통해 비선형성을 부여한다.\n",
    "\n",
    "공간 정보 축소: 풀링 연산으로 특징 맵을 압축하여 중요 정보만 보존한다.\n",
    "\n",
    "특징 벡터화 및 분류: 추출된 특징을 1차원 벡터로 변환한 후 완전 연결층을 통해 최종 클래스를 예측한다.\n",
    "\n",
    "이러한 과정은 반복적으로 이루어지며, 모델은 점차 복잡한 특징을 학습해 나간다. 예를 들어 초기 합성곱층에서는 단순한 선이나 모서리를 감지하고, 이후 층으로 갈수록 더 고차원적인 패턴(예: 눈, 얼굴 형태 등)을 인식할 수 있게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bdfeec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) \n",
    "]) # normalization 0.1307, 0.3081은 MNIST 데이터셋의 평균과 표준편차\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c634724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CNN 모델 정의\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)     # 1채널 입력, 10개 필터, 5x5\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)  # 숫자 0~9\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))   # 28x28 -> 12x12\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))   # 12x12 -> 4x4\n",
    "        x = x.view(-1, 320)                          # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# 3. 학습 루프\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 함수\n",
    "def train(model, loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)  # Negative log likelihood\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Train Epoch {epoch} [{batch_idx * len(data)}/{len(loader.dataset)}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 실행\n",
    "for epoch in range(1, 4):  # 간단히 3 에폭만\n",
    "    train(model, train_loader, optimizer, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0b258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import sys, os\n",
    "sys.path.append('C:/Users/KimDongyoung/Desktop/Github/my_git/mygit/DEEPLEARNING/퍼셉트론/mnist.py')\n",
    "import pickle\n",
    "from mnist import load_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순한 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 곱셈 계층\n",
    "\n",
    "class MulLayer:\n",
    "  def __init__(self):\n",
    "    self.x = None\n",
    "    self.y = None\n",
    "  \n",
    "  def forward(self,x,y):  # 순전파\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "    out = x * y   # z = x * y\n",
    "\n",
    "    return out\n",
    "  \n",
    "  def backward(self,dout): # 역전파, dout은 상류에서 넘어온 미분이다\n",
    "    dx = dout * self.y   # 상류에서 넘어온 미분(dout)에 y를 곱한다\n",
    "    dy = dout * self.x\n",
    "\n",
    "    return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 덧셈 계층\n",
    "\n",
    "class AddLayer:\n",
    "  def __init__(self):\n",
    "    pass # 덧셈 계층에서는 초기화가 필요 없다\n",
    "  \n",
    "  def forward(self,x,y): \n",
    "    out = x + y\n",
    "    return out\n",
    "  def backward(self,dout):\n",
    "    dx = dout * 1\n",
    "    dy = dout * 1\n",
    "    return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n",
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)  # apple_price = apple * apple_num = 200\n",
    "price = mul_tax_layer.forward(apple_price, tax) # price = apple_price * tax = 220\n",
    "\n",
    "print(price)\n",
    "\n",
    "# 역전파\n",
    "\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice) # dout = 1, dapple_price = 1.1 = dout*tax, dtax = 200 = dout*apple_price\n",
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price) # dapple = 2.2 = dapple_price*apple_num, dapple_num = 110 = dapple_price*apple\n",
    "\n",
    "print(dapple, dapple_num, dtax)  # 2.2 110 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "110.00000000000001 2.2 165.0 3.3000000000000003 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100 # 사과가격\n",
    "apple_num = 2 # 사과개수\n",
    "orange = 150 # 오렌지가격\n",
    "orange_num = 3 # 오렌지개수\n",
    "tax = 1.1 # 소비세\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forward(apple_num, apple) # 사과가격 * 사과개수\n",
    "orange_price = mul_orange_layer.forward(orange_num, orange) # 오렌지가격 * 오렌지개수\n",
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price) # 사과가격 + 오렌지가격\n",
    "price = mul_tax_layer.forward(all_price, tax) # 소비세를 포함한 총 가격\n",
    "\n",
    "# 역전파\n",
    "\n",
    "dprice = 1\n",
    "dall_price, dtax = mul_tax_layer.backward(dprice) # 소비세 계층 역전파\n",
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price) # 사과와 오렌지를 더한 가격 계층 역전파\n",
    "dapple_num, dapple = mul_apple_layer.backward(dapple_price)\n",
    "dorange_num, dorange = mul_orange_layer.backward(dorange_price)\n",
    "\n",
    "print(price) # 715\n",
    "print(dapple_num, dapple, dorange_num, dorange, dtax) # 2.2 110 3.3 165 650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 활성화 함수(Relu, Sigmoid) 계층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순전파와 역전파를 포함한 ReLU 계층 구현\n",
    "\n",
    "class Relu: \n",
    "  def __init__(self):\n",
    "    self.mask = None # mask는 True/False로 구성된 넘파이 배열, 순전파의 입력인 x의 원소 값이 0 이하인 인덱스는 True, 그 외(0보다 큰 원소)는 False로 유지\n",
    "  \n",
    "  # 순전파\n",
    "  def forward(self,x):\n",
    "    self.mask = (x <= 0) # x의 원소 값이 0 이하인 인덱스를 True로 설정\n",
    "    out = x.copy() # 입력 x를 복사하여 out에 저장\n",
    "    out[self.mask] = 0 # mask의 원소가 True인 인덱스에 대응하는 원소를 0으로 설정, 즉 x가 0보다 작으면 0으로 변환, 그 외는 그대로 유지\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  # 역전파\n",
    "  def backward(self,dout):\n",
    "    dout[self.mask] = 0\n",
    "    dx = dout # 순전파 때의 입력인 x가 0보다 작으면 역전파 때의 값은 0, 그 외는 상류 값을 그대로 전달한다. \n",
    "    \n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순전파와 역전파를 포함한 Sigmoid 계층 구현\n",
    "\n",
    "class Sigmoid:\n",
    "  def __init__(self):\n",
    "    self.out = None\n",
    "  \n",
    "  def forward(self,x):\n",
    "    out = 1 / 1 + np.exp(-x)  # y = 1 / 1 + exp(-x)\n",
    "    self.out = out\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  def backward(self,dout):\n",
    "    dx = dout * (1.0 - self.out) * self.out   # y = 1 / 1 + exp(-x)의 미분은 y(1-y)이다\n",
    "    \n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine, Softmax 계층 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망의 순전파 때 수행하는 행렬의 내적을 기하학에서는 어파인 변환(Affine Transformation)이라고 불러서 Affine 계층이라는 이름을 사용한다.\n",
    "# Affine 계층은 가중치 신호의 총합을 계산하고, 편향을 더한다.\n",
    "\n",
    "# N개의 데이터를 묶어 순전파와 역전파를 수행한 Affine 계층 구현\n",
    "class Affine: \n",
    "  def __init__(self,w,b): # 이 두 매개변수는 가중치와 편향을 의미하며 신경망이 학습될 시 갱신된다\n",
    "    self.w = w  # 가중치\n",
    "    self.b = b  # 편향\n",
    "    self.x = None # 입력\n",
    "    self.dw = None # 가중치의 미분\n",
    "    self.db = None # 편향의 미분\n",
    "   \n",
    "  # 순전파  \n",
    "  def forward(self, x):\n",
    "    self.x = x\n",
    "    out = np.dot(x,self.w) + self.b  # y = WX + B\n",
    "    \n",
    "    return out\n",
    "   \n",
    "  # 역전파  \n",
    "  def backward(self,dout):\n",
    "    dx = np.dot(dout,self.w.T)  # dx = dL/dy * W^T, self.w.T는 self.w의 전치행렬, 입력 x에 대한 상류 값의 미분으로 이전 층으로 전파해야 할 값이다\n",
    "    self.dw = np.dot(self.x.T,dout) # dw = X^T * dL/dy, self.x.T는 self.x의 전치행렬\n",
    "    self.db = np.sum(dout, axis = 0) # db = dL/dy의 각 원소의 총합이다, axis = 0은 행 방향으로 더한다\n",
    "    \n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x - np.max(x, axis=1, keepdims=True) # 오버플로 대책\n",
    "        x = np.exp(x)\n",
    "        x /= np.sum(x, axis=1, keepdims=True)\n",
    "    elif x.ndim == 1:\n",
    "        x = x - np.max(x) # 오버플로 대책\n",
    "        x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return x\n",
    "  \n",
    "  # 평균 손실함수\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size) # t는 실제 정답 레이블\n",
    "        y = y.reshape(1, y.size) # y는 신경망의 출력\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size  # np.log(0)이 -inf가 되는 것을 방지하기 위해 아주 작은 delta(1e-7)를 더해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax-with-Loss 계층\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "  def __init__(self):\n",
    "    self.loss = None # 손실\n",
    "    self.y = None # softmax의 출력\n",
    "    self.t = None # 정답 레이블(원-핫 인코딩 형태)\n",
    "    \n",
    "  def forward(self,x,t):\n",
    "    self.t = t\n",
    "    self.y = softmax(x)\n",
    "    self.loss = cross_entropy_error(self.y,self.t)\n",
    "    \n",
    "    # 순전파의 결과인 손실을 반환한다\n",
    "    return self.loss\n",
    "  \n",
    "  def backward(self,dout=1):\n",
    "    batch_size = self.t.shape[0]\n",
    "    dx = (self.y - self.t) / batch_size # 역전파의 결과로는 데이터의 개수로 나눠서 데이터 1개당 오차를 앞 계층으로 전파한다\n",
    "    \n",
    "    return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2층 신경망 TwoLayerNet 계층 구현  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "  def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "    # 가중치 초기화\n",
    "    self.params = {}\n",
    "    self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size) # 가중치 개수 = input_size x hidden_size\n",
    "    self.params['b1'] = np.zeros(hidden_size) # 편향 개수 = hidden_size\n",
    "    self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) # 가중치 개수 = hidden_size x output_size\n",
    "    self.params['b2'] = np.zeros(output_size) # 편향 개수 = output_size\n",
    "    \n",
    "    # 신경망 계층 보관 (Affine 계층과 ReLU 계층)\n",
    "    # 순서가 있는 딕셔너리를 사용하여 계층을 보관한다\n",
    "    self.layers = OrderedDict()\n",
    "    self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "    self.layers['Relu1'] = Relu()\n",
    "    self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "    \n",
    "    # 마지막 계층, Softmax-with-Loss 계층\n",
    "    self.lastLayer = SoftmaxWithLoss()\n",
    "    \n",
    "  def predict(self, x):\n",
    "    for layer in self.layers.values():\n",
    "      x = layer.forward(x) # Affine 계층의 forward() 메서드와 ReLU 계층의 forward() 메서드를 호출한다 -> 순전파를 수행한다\n",
    "      \n",
    "    return x # 순전파의 결과를 반환한다. Affine 계층과 ReLU 계층을 통과한 결과가 마지막 Affine 계층을 통과하면서 예측이 완료된다\n",
    "  \n",
    "  # x: 입력 데이터, t: 정답 레이블\n",
    "  # 손실 함수의 값이 반환된다\n",
    "  def loss(self, x, t):\n",
    "    y = self.predict(x) # predict() 메서드를 호출하여 예측을 수행한다. predict() 메서드에서 반환된 x값이 y에 저장된다, y는 예측 결과이다\n",
    "    return self.lastLayer.forward(y, t) # self.lastLayer.forward()는 Softmax-with-Loss 계층의 forward() 메서드를 호출한다. 이 메서드는 손실을 반환한다\n",
    "  \n",
    "  def accuracy(self, x, t):\n",
    "    y = self.predict(x) # 예측 결과\n",
    "    y = np.argmax(y, axis = 1) # 예측 결과 중 가장 큰 값의 인덱스를 반환한다\n",
    "    if t.ndim != 1: # 정답 레이블이 원-핫 인코딩 형태일 때, 정답 레이블을 1차원 배열로 변환한다\n",
    "      t = np.argmax(t, axis = 1) # 정답 레이블 중 가장 큰 값의 인덱스를 반환한다. 형태의 원-핫 인코딩에서 1의 인덱스를 반환한다\n",
    "      \n",
    "    accuracy = np.sum(y == t) / float(x.shape[0]) # 정확도를 계산한다. 정확도는 (예측 결과와 정답 레이블이 같은 개수) / (데이터의 총 개수)로 계산한다\n",
    "    return accuracy\n",
    "  \n",
    "  # 수치 미분을 사용하여 기울기를 계산하는 방법\n",
    "  def numerical_gradient(self, x, t):\n",
    "    loss_W = lambda W: self.loss(x, t)\n",
    "    \n",
    "    grads = {}\n",
    "    grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "    grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "    grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "    grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "    \n",
    "    return grads\n",
    "  \n",
    "  # 오차역전파방법을 사용하여 기울기를 계산하는 방법\n",
    "  def gradient(self, x, t):\n",
    "    self.loss(x, t) # loss() 메서드를 호출하여 손실을 계산한다\n",
    "    \n",
    "    dout = 1\n",
    "    dout = self.lastLayer.backward(dout) # self.lastLayer.backward()를 호출하여 역전파를 수행한다 -> softmax-with-loss 계층의 역전파를 수행한다\n",
    "    \n",
    "    layers = list(self.layers.values()) # layers에 순서가 있는 딕셔너리인 self.layers의 값을 리스트로 변환하여 저장한다\n",
    "    layers.reverse() # layers의 순서를 뒤집는다\n",
    "    for layer in layers: # layers의 각 원소인 layer에 대해 반복한다. layers는 Affine 계층과 ReLU 계층이다. 역으로 Affine2 -> ReLU1 -> Affine1 순서로 진행된다. \n",
    "      dout = layer.backward(dout) # layer.backward()를 호출하여 역전파를 수행한다. -> Affine 계층과 ReLU 계층의 역전파를 수행한다\n",
    "     \n",
    "    # 결과 저장  \n",
    "    grads = {} # 기울기를 저장할 딕셔너리\n",
    "    grads['W1'] = self.layers['Affine1'].dw # self.layers['Affine1'].dw에는 가중치 W1에 대한 기울기가 저장된다. Affine 계층의 self.dw에 저장된다\n",
    "    grads['b1'] = self.layers['Affine1'].db # self.layers['Affine1'].db에는 편향 b1에 대한 기울기가 저장된다. Affine 계층의 self.db에 저장된다\n",
    "    grads['W2'] = self.layers['Affine2'].dw # self.layers['Affine2'].dw에는 가중치 W2에 대한 기울기가 저장된다. Affine 계층의 self.dw에 저장된다\n",
    "    grads['b2'] = self.layers['Affine2'].db\n",
    "    print(grads['b1'])\n",
    "    print('-'*50)\n",
    "    print(grads['b2'])\n",
    "    print('-'*50)\n",
    "    print(grads['W1'])\n",
    "    print('-'*50)\n",
    "    print(grads['W2'])\n",
    "    print('-'*50)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00272464  0.00535511 -0.00327553 -0.00491696  0.          0.\n",
      "  0.00538231 -0.00699602  0.00200531  0.00493462  0.00485425 -0.00210157\n",
      " -0.00345913 -0.00398161 -0.00357317  0.00887581 -0.00216292  0.\n",
      " -0.003773    0.00531618  0.00484305  0.00267067  0.         -0.00473203\n",
      "  0.0011657   0.00017331 -0.00071017  0.00587813 -0.00658407  0.00502697\n",
      "  0.00300069  0.          0.          0.00296616  0.00081108 -0.00629369\n",
      "  0.00299486  0.          0.00613982  0.00277221  0.00046128  0.00202868\n",
      "  0.00012037 -0.00165971 -0.000817   -0.00203699  0.00026662 -0.00194398\n",
      "  0.          0.        ]\n",
      "--------------------------------------------------\n",
      "[-0.23368645  0.09995839  0.09960928  0.10009405 -0.23370426 -0.23287962\n",
      "  0.10016377  0.10045478  0.10023242  0.09975763]\n",
      "--------------------------------------------------\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "--------------------------------------------------\n",
      "[[ 1.94480503e-03  1.95403954e-03  1.95072894e-03  1.95618514e-03\n",
      "  -1.75740196e-02  1.95522774e-03  1.94855855e-03  1.94737808e-03\n",
      "   1.96472191e-03  1.95237471e-03]\n",
      " [ 2.12151710e-04  2.13159070e-04  2.12797928e-04  2.13393125e-04\n",
      "  -1.91708591e-03  2.13288685e-04  2.12561168e-04  2.12432395e-04\n",
      "   2.14324370e-04  2.12977459e-04]\n",
      " [-7.43718809e-02  1.80956083e-02  1.80227276e-02  1.81247726e-02\n",
      "   1.14150179e-02 -6.38953749e-02  1.81734966e-02  1.82532062e-02\n",
      "   1.81253473e-02  1.80570793e-02]\n",
      " [ 2.76004024e-05  2.77711406e-05  2.75191966e-05  2.77448397e-05\n",
      "   2.75089488e-05 -2.49281347e-04  2.78558514e-05  2.80217050e-05\n",
      "   2.77521909e-05  2.75070718e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-7.91002167e-03  6.20745661e-03  6.16431502e-03  6.20843042e-03\n",
      "   6.16128418e-03 -4.17026895e-02  6.23043969e-03  6.26385008e-03\n",
      "   6.20901794e-03  6.16791727e-03]\n",
      " [ 7.31901862e-03  8.27186355e-03  8.23016288e-03  8.27347847e-03\n",
      "  -3.57771081e-02 -2.94070215e-02  8.27156927e-03  8.29177133e-03\n",
      "   8.29367476e-03  8.23259075e-03]\n",
      " [-7.77817393e-03  6.89696748e-03  6.88821271e-03  6.90868151e-03\n",
      "  -4.74441201e-02  6.91560916e-03  6.89037736e-03  6.89200147e-03\n",
      "   6.93172520e-03  6.89871913e-03]\n",
      " [-4.58593554e-02  1.19522911e-02  1.19052579e-02  1.19711188e-02\n",
      "   1.90959806e-03 -3.98289600e-02  1.19994986e-02  1.20492895e-02\n",
      "   1.19740562e-02  1.19272053e-02]\n",
      " [ 1.42281068e-03  8.59643901e-03  8.53497116e-03  8.59449639e-03\n",
      "  -4.81614679e-03 -5.67448865e-02  8.61688701e-03  8.65758886e-03\n",
      "   8.60172041e-03  8.53611978e-03]\n",
      " [-1.96920585e-02  1.01399927e-02  1.00758554e-02  1.01448789e-02\n",
      "   1.00705484e-02 -6.13811046e-02  1.01794829e-02  1.02322985e-02\n",
      "   1.01453310e-02  1.00847754e-02]\n",
      " [-1.28712518e-02  1.42424779e-03  1.42469429e-03  1.42985254e-03\n",
      "   1.42341758e-03  1.43921259e-03  1.43270022e-03  1.43749058e-03\n",
      "   1.42915837e-03  1.43047787e-03]\n",
      " [-2.71496186e-02  4.60514344e-03  4.60369176e-03  4.61917417e-03\n",
      "  -9.80883608e-03  4.63925472e-03  4.61986980e-03  4.62963720e-03\n",
      "   4.62393285e-03  4.61775075e-03]\n",
      " [-4.40190456e-02  5.87386363e-03  5.86722394e-03  5.89256689e-03\n",
      "   5.86243512e-03 -3.08878711e-03  5.90611664e-03  5.92823032e-03\n",
      "   5.89038361e-03  5.88701251e-03]\n",
      " [ 1.13070668e-03  6.25355373e-03  6.23442541e-03  6.25921241e-03\n",
      "  -3.82443689e-02 -6.65476207e-03  6.24802898e-03  6.25477897e-03\n",
      "   6.27875475e-03  6.23967009e-03]\n",
      " [-2.68215121e-02  4.78929856e-03  4.77539866e-03  4.80013400e-03\n",
      "   4.77197092e-03 -1.15481569e-02  4.81298837e-03  4.83337764e-03\n",
      "   4.79903388e-03  4.78746704e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.38949933e-03  1.39809488e-03  1.38541115e-03  1.39677080e-03\n",
      "   1.38489524e-03 -1.25496817e-02  1.40235951e-03  1.41070915e-03\n",
      "   1.39714088e-03  1.38480074e-03]\n",
      " [-7.98340730e-04  4.91157063e-03  4.87232637e-03  4.90968349e-03\n",
      "   4.87021535e-03 -3.84329682e-02  4.92818562e-03  4.95604121e-03\n",
      "   4.91055776e-03  4.87272847e-03]\n",
      " [-1.49401680e-02  4.18808083e-03  4.18480929e-03  4.19808338e-03\n",
      "  -1.86328706e-02  4.20948184e-03  4.19297941e-03  4.19800614e-03\n",
      "   4.20713084e-03  4.19446689e-03]\n",
      " [ 4.12406669e-03  4.14549246e-03  4.12895075e-03  4.14740597e-03\n",
      "  -2.44025610e-02 -8.72318591e-03  4.14141844e-03  4.14739815e-03\n",
      "   4.16022204e-03  4.13079242e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-5.55171693e-02  7.22099443e-03  7.21414437e-03  7.24466985e-03\n",
      "   7.20818352e-03 -2.40071988e-03  7.26104777e-03  7.28786830e-03\n",
      "   7.24188069e-03  7.23910020e-03]\n",
      " [ 5.06102971e-03  5.08871328e-03  5.06123420e-03  5.08907370e-03\n",
      "  -2.02470399e-02 -2.04086232e-02  5.08940547e-03  5.10313993e-03\n",
      "   5.10081535e-03  5.06225147e-03]\n",
      " [ 2.47833515e-03  2.49065907e-03  2.48356832e-03  2.49259809e-03\n",
      "  -1.85150047e-02 -1.39016364e-03  2.48595137e-03  2.48700577e-03\n",
      "   2.50188220e-03  2.48516841e-03]\n",
      " [-3.48469580e-02  1.02431662e-02  1.01986093e-02  1.02571109e-02\n",
      "   1.74251373e-03 -3.86784815e-02  1.02824067e-02  1.03263087e-02\n",
      "   1.02599171e-02  1.02154069e-02]\n",
      " [-2.11698726e-02  4.14327758e-03  4.12934974e-03  4.15166159e-03\n",
      "   4.12649129e-03 -1.20151905e-02  4.16318712e-03  4.18135502e-03\n",
      "   4.15086234e-03  4.13887842e-03]\n",
      " [ 3.91812059e-03  3.93881901e-03  3.92133387e-03  3.94014702e-03\n",
      "  -2.07932456e-02 -1.06792530e-02  3.93635132e-03  3.94360892e-03\n",
      "   3.95134060e-03  3.92277725e-03]\n",
      " [-1.63256250e-02  1.80648592e-03  1.80705226e-03  1.81359488e-03\n",
      "   1.80543291e-03  1.82546697e-03  1.81720681e-03  1.82328280e-03\n",
      "   1.81271440e-03  1.81438803e-03]\n",
      " [ 3.40404012e-03  3.42509777e-03  3.39402476e-03  3.42185400e-03\n",
      "   3.39276088e-03 -3.07446136e-02  3.43554540e-03  3.45600063e-03\n",
      "   3.42276064e-03  3.39252937e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-3.90094876e-03  4.31653246e-04  4.31788571e-04  4.33351905e-04\n",
      "   4.31401632e-04  4.36188698e-04  4.34214962e-04  4.35666800e-04\n",
      "   4.33141519e-04  4.33541427e-04]\n",
      " [-3.22696636e-02  5.14101102e-03  5.12934499e-03  5.15433521e-03\n",
      "   5.12548265e-03 -8.93312643e-03  5.16744074e-03  5.18842272e-03\n",
      "   5.15289349e-03  5.14385919e-03]\n",
      " [-1.22271772e-02  6.47658938e-03  6.46935346e-03  6.48898169e-03\n",
      "  -3.96485878e-02  6.49895246e-03  6.47468960e-03  6.47816165e-03\n",
      "   6.50823784e-03  6.48079889e-03]\n",
      " [ 1.51466914e-03  1.52403900e-03  1.51021268e-03  1.52259564e-03\n",
      "   1.50965030e-03 -1.36801905e-02  1.52868780e-03  1.53778960e-03\n",
      "   1.52299906e-03  1.50954729e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-2.85424595e-02  4.57342313e-03  4.56297286e-03  4.58521886e-03\n",
      "   4.44891052e-03 -8.00016599e-03  4.59682277e-03  4.61545822e-03\n",
      "   4.58399408e-03  4.57582505e-03]\n",
      " [-3.00196042e-03  2.51520526e-03  2.51204564e-03  2.51952394e-03\n",
      "  -1.71373087e-02  2.52216675e-03  2.51294604e-03  2.51360373e-03\n",
      "   2.52784751e-03  2.51593021e-03]\n",
      " [-1.71994643e-02  4.01177110e-03  3.99519907e-03  4.01828358e-03\n",
      "   3.99260477e-03 -1.49177472e-02  4.03010027e-03  4.04854934e-03\n",
      "   4.01775701e-03  4.00294645e-03]\n",
      " [ 2.11265028e-03  2.12513289e-03  2.10887676e-03  2.12395832e-03\n",
      "  -1.98638323e-03 -1.49873390e-02  2.12921578e-03  2.13921251e-03\n",
      "   2.12620267e-03  2.10847299e-03]\n",
      " [ 2.95811409e-03  2.97216010e-03  2.96712456e-03  2.97542363e-03\n",
      "  -2.67306770e-02  2.97396738e-03  2.96382332e-03  2.96202779e-03\n",
      "   2.98840834e-03  2.96962783e-03]\n",
      " [-3.58547986e-02  5.95864419e-03  5.95691106e-03  5.97700391e-03\n",
      "  -1.19689894e-02  6.00349710e-03  5.97833089e-03  5.99125599e-03\n",
      "   5.98280999e-03  5.97533493e-03]\n",
      " [ 1.42879194e-03  1.43763055e-03  1.42458815e-03  1.43626903e-03\n",
      "   1.42405765e-03 -1.29045647e-02  1.44201578e-03  1.45060154e-03\n",
      "   1.43664958e-03  1.42396048e-03]\n",
      " [ 2.03100508e-03  2.04356903e-03  2.02502946e-03  2.04163365e-03\n",
      "   2.02427537e-03 -1.83436341e-02  2.04980256e-03  2.06200708e-03\n",
      "   2.04217459e-03  2.02413724e-03]\n",
      " [-1.67463149e-02  1.85303669e-03  1.85361763e-03  1.86032884e-03\n",
      "   1.85195655e-03  1.87250685e-03  1.86403384e-03  1.87026641e-03\n",
      "   1.85942567e-03  1.86114243e-03]\n",
      " [-2.36780328e-02  4.64448006e-03  4.64066216e-03  4.65713620e-03\n",
      "  -1.13996093e-02  2.49456441e-03  4.65738551e-03  4.66720898e-03\n",
      "   4.66283130e-03  4.65337349e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize = True, one_hot_label = True)\n",
    "\n",
    "network = TwoLayerNet(input_size = 784, hidden_size = 50, output_size = 10)\n",
    "\n",
    "# 미니배치 학습 구현\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "get_backpropagation = network.gradient(x_batch, t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
